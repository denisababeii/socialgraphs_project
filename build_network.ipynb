{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950ade85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "from urllib.request import urlopen, Request\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502a660",
   "metadata": {},
   "source": [
    "# Build network based on nodes and edges from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4a2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.read_csv('Nodes.csv')\n",
    "edges_df = pd.read_csv('Edges.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0152a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nx.DiGraph()\n",
    "\n",
    "# Feature to include from dataset\n",
    "features = ['Name', 'NameURL', 'Link', 'birthcity', 'countryName', 'continentName', 'birthyear', 'deathyear', 'gender', 'occupation', 'industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715e5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nodes\n",
    "for index, row in nodes_df.iterrows():\n",
    "    network.add_node(row['Id'], **row[features].to_dict())\n",
    "\n",
    "# Handling weird numberings\n",
    "number_formatted_nodes = {\n",
    "    \"1,00E+03\": \"1000\",\n",
    "    \"2,00E+03\": \"2000\",\n",
    "    \"3,00E+03\": \"3000\",\n",
    "    \"4,00E+03\": \"4000\",\n",
    "    \"5,00E+03\": \"5000\",\n",
    "    \"6,00E+03\": \"6000\",\n",
    "    \"7,00E+03\": \"7000\",\n",
    "    \"8,00E+03\": \"8000\",\n",
    "    \"9,00E+03\": \"9000\",\n",
    "    \"1,00E+04\": \"10000\",\n",
    "    \"1,10E+04\": \"11000\"\n",
    "}\n",
    "\n",
    "# Load edges\n",
    "for index, row in edges_df.iterrows():\n",
    "    try:\n",
    "        source_id = row['Source']\n",
    "        target_id = row['Target']\n",
    "        if row['Source'] in number_formatted_nodes:\n",
    "            source_id = number_formatted_nodes[row['Source']]\n",
    "        if row['Target'] in number_formatted_nodes:\n",
    "            target_id = number_formatted_nodes[row['Target']]\n",
    "        network.add_edge(int(source_id), int(target_id))\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding edge from {row['Source']} to {row['Target']}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76a19e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikitext(title):\n",
    "    baseurl = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    query = f\"{baseurl}?{urlencode(params)}\"\n",
    "    wikiurl = Request(query, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    wikiresponse = urlopen(wikiurl)\n",
    "    wikidata = wikiresponse.read()\n",
    "    wikitext = json.loads(wikidata.decode(\"utf-8\"))\n",
    "    pageId = str(list(wikitext[\"query\"][\"pages\"].keys())[0])\n",
    "    page_text = wikitext[\"query\"][\"pages\"][pageId]['revisions'][0]['slots']['main']['*']\n",
    "    return page_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = 0\n",
    "milestone = 10 # percent\n",
    "total = network.number_of_nodes()\n",
    "for node in network.nodes(data=True):\n",
    "    nameURL = node[1]['NameURL']\n",
    "    try:\n",
    "        wikitext = get_wikitext(nameURL)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching wikitext for {nameURL}: {e}\")\n",
    "        continue\n",
    "    with open(f'wikipages/{nameURL}.txt', 'w+', encoding='utf-8') as f:\n",
    "        f.write(wikitext)\n",
    "    progress += 1\n",
    "    if (progress / total) * 100 >= milestone:\n",
    "        print(f\"Progress: {progress}/{total} ({(progress / total) * 100:.2f}%)\")\n",
    "        milestone += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70a4ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ Failure: 'wikipages/Valdemar_IV_Atterdag_of_Denmark.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Nicolas_de_Caritat,_marquis_de_Condorcet.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Donatien_Alphonse_François_de_Sade,_Marquis_de_Sade.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Geoffrey_V_Plantagenet,_Count_of_Anjou.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Charles_the_Bald,_Holy_Roman_Emperor.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Clemens_Maria_Wenzeslaus_von_Brentano.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Dimitris_Kraniotris.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Edgar_the_Peaceful_of_England.txt' was NOT found.\n",
      "\n",
      "❌ Failure: 'wikipages/Arnulf_of_Carinthia,_Holy_Roman_Emperor.txt' was NOT found.\n"
     ]
    }
   ],
   "source": [
    "# Check whether all pages are fetched\n",
    "for node in network.nodes(data=True):\n",
    "    nameURL = node[1]['NameURL']\n",
    "    file_path = Path(f\"wikipages/{nameURL}.txt\")\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"\\n❌ Failure: '{file_path}' was NOT found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c19edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_to_new_nameURL = {\n",
    "    \"Valdemar_IV_Atterdag_of_Denmark\": \"Valdemar_IV_of_Denmark\",\n",
    "    \"Nicolas_de_Caritat,_marquis_de_Condorcet\": \"Marquis_de_Condorcet\",\n",
    "    \"Donatien_Alphonse_François_de_Sade,_Marquis_de_Sade\": \"Marquis_de_Sade\",\n",
    "    \"Geoffrey_V_Plantagenet,_Count_of_Anjou\": \"Geoffrey_Plantagenet,_Count_of_Anjou\",\n",
    "    \"Charles_the_Bald,_Holy_Roman_Emperor\": \"Charles_the_Bald\",\n",
    "    \"Clemens_Maria_Wenzeslaus_von_Brentano\" : \"Clemens_Brentano\",\n",
    "    \"Dimitris_Kraniotris\": \"Dimitris_P._Kraniotis\",\n",
    "    \"Edgar_the_Peaceful_of_England\": \"Edgar,_King_of_England\",\n",
    "    \"Arnulf_of_Carinthia,_Holy_Roman_Emperor\": \"Arnulf_of_Carinthia\"\n",
    "}\n",
    "\n",
    "for nameURL, newNameURL in old_to_new_nameURL.items():\n",
    "    node_id = next((n for n, attr in network.nodes(data=True) if attr['NameURL'] == nameURL), None)\n",
    "    network.nodes[node_id]['redirectNameURL'] = newNameURL\n",
    "    try:\n",
    "        wikitext = get_wikitext(old_to_new_nameURL[nameURL])\n",
    "        with open(f'wikipages/{newNameURL}.txt', 'w+', encoding='utf-8') as f:\n",
    "            f.write(wikitext)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching wikitext for {nameURL}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa45a1",
   "metadata": {},
   "source": [
    "Handle duplicated nodes in nodes_df based on 'NameURL' column\n",
    "\n",
    "* Remove the first one for most because it doesn't have any edges pointing to it\n",
    "\n",
    "* \"James_Connolly\" is a special case because there is the UK one and US one. A bit problematic so we will remove both\n",
    "\n",
    "* \"Matthew_Perry\" is another special case, because the second node is the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98cd9796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>en_curid</th>\n",
       "      <th>Name</th>\n",
       "      <th>NameURL</th>\n",
       "      <th>Link</th>\n",
       "      <th>birthcity</th>\n",
       "      <th>countryName</th>\n",
       "      <th>countryCode_alpha2</th>\n",
       "      <th>countryCode_alpha3</th>\n",
       "      <th>...</th>\n",
       "      <th>harmonicClosenessCentrality</th>\n",
       "      <th>betweenessCentrality</th>\n",
       "      <th>authority</th>\n",
       "      <th>hub</th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>degree</th>\n",
       "      <th>clustering</th>\n",
       "      <th>eigenCentrality</th>\n",
       "      <th>BCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2026</td>\n",
       "      <td>2025</td>\n",
       "      <td>157272</td>\n",
       "      <td>Alexandre Dumas</td>\n",
       "      <td>Alexandre_Dumas</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alexandre_Dumas</td>\n",
       "      <td>VILLERS-COTTERÌ_TS</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>FR</td>\n",
       "      <td>FRA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239137</td>\n",
       "      <td>9.981295e+10</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.055658</td>\n",
       "      <td>0.035416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>8040</td>\n",
       "      <td>8039</td>\n",
       "      <td>190391</td>\n",
       "      <td>Dido</td>\n",
       "      <td>Dido</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dido</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237527</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>8235</td>\n",
       "      <td>8234</td>\n",
       "      <td>46402</td>\n",
       "      <td>Jane Seymour</td>\n",
       "      <td>Jane_Seymour</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jane_Seymour</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213809</td>\n",
       "      <td>5.191401e+09</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0.400735</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.007975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9842</th>\n",
       "      <td>9843</td>\n",
       "      <td>9842</td>\n",
       "      <td>2293356</td>\n",
       "      <td>Ben Foster</td>\n",
       "      <td>Ben_Foster</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ben_Foster</td>\n",
       "      <td>ROYAL LEAMINGTON SPA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235723</td>\n",
       "      <td>2.451505e+10</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.002570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>9881</td>\n",
       "      <td>9880</td>\n",
       "      <td>168309</td>\n",
       "      <td>James Connolly</td>\n",
       "      <td>James_Connolly</td>\n",
       "      <td>https://en.wikipedia.org/wiki/James_Connolly</td>\n",
       "      <td>COWGATE</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232704</td>\n",
       "      <td>4.995274e+09</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.003610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>9901</td>\n",
       "      <td>9900</td>\n",
       "      <td>233338</td>\n",
       "      <td>Matthew Perry</td>\n",
       "      <td>Matthew_Perry</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Matthew_Perry</td>\n",
       "      <td>WILLIAMSTOWN</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10099</th>\n",
       "      <td>10100</td>\n",
       "      <td>10099</td>\n",
       "      <td>1624</td>\n",
       "      <td>Andrew Johnson</td>\n",
       "      <td>Andrew_Johnson</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Andrew_Johnson</td>\n",
       "      <td>RALEIGH</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229379</td>\n",
       "      <td>2.728845e+10</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>48</td>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.082999</td>\n",
       "      <td>0.066761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     Id  en_curid             Name          NameURL  \\\n",
       "2025         2026   2025    157272  Alexandre Dumas  Alexandre_Dumas   \n",
       "8039         8040   8039    190391             Dido             Dido   \n",
       "8234         8235   8234     46402     Jane Seymour     Jane_Seymour   \n",
       "9842         9843   9842   2293356       Ben Foster       Ben_Foster   \n",
       "9880         9881   9880    168309   James Connolly   James_Connolly   \n",
       "9900         9901   9900    233338    Matthew Perry    Matthew_Perry   \n",
       "10099       10100  10099      1624   Andrew Johnson   Andrew_Johnson   \n",
       "\n",
       "                                                Link             birthcity  \\\n",
       "2025   https://en.wikipedia.org/wiki/Alexandre_Dumas    VILLERS-COTTERÌ_TS   \n",
       "8039              https://en.wikipedia.org/wiki/Dido                LONDON   \n",
       "8234      https://en.wikipedia.org/wiki/Jane_Seymour                LONDON   \n",
       "9842        https://en.wikipedia.org/wiki/Ben_Foster  ROYAL LEAMINGTON SPA   \n",
       "9880    https://en.wikipedia.org/wiki/James_Connolly               COWGATE   \n",
       "9900     https://en.wikipedia.org/wiki/Matthew_Perry          WILLIAMSTOWN   \n",
       "10099   https://en.wikipedia.org/wiki/Andrew_Johnson               RALEIGH   \n",
       "\n",
       "          countryName countryCode_alpha2 countryCode_alpha3  ...  \\\n",
       "2025           FRANCE                 FR                FRA  ...   \n",
       "8039   UNITED KINGDOM                 GB                GBR  ...   \n",
       "8234   UNITED KINGDOM                 GB                GBR  ...   \n",
       "9842   UNITED KINGDOM                 GB                GBR  ...   \n",
       "9880   UNITED KINGDOM                 GB                GBR  ...   \n",
       "9900    UNITED STATES                 US                USA  ...   \n",
       "10099   UNITED STATES                 US                USA  ...   \n",
       "\n",
       "       harmonicClosenessCentrality  betweenessCentrality authority       hub  \\\n",
       "2025                      0.239137          9.981295e+10  0.000224  0.000110   \n",
       "8039                      0.237527          0.000000e+00  0.000000  0.000174   \n",
       "8234                      0.213809          5.191401e+09  0.000046  0.000028   \n",
       "9842                      0.235723          2.451505e+10  0.000095  0.000108   \n",
       "9880                      0.232704          4.995274e+09  0.000031  0.000106   \n",
       "9900                      0.000000          0.000000e+00  0.000000  0.000000   \n",
       "10099                     0.229379          2.728845e+10  0.000212  0.000132   \n",
       "\n",
       "       indegree  outdegree degree clustering eigenCentrality       BCI  \n",
       "2025         33         15     48   0.040703        0.055658  0.035416  \n",
       "8039          0         14     14   0.076923        0.000000  0.001153  \n",
       "8234         14          9     23   0.400735        0.030500  0.007975  \n",
       "9842          7          8     15   0.030303        0.011723  0.002570  \n",
       "9880          6          5     11   0.088889        0.006121  0.003610  \n",
       "9900          0          0      0   0.000000        0.000000  0.001205  \n",
       "10099        28         20     48   0.206456        0.082999  0.066761  \n",
       "\n",
       "[7 rows x 43 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_index = nodes_df.index[nodes_df.duplicated(subset=['NameURL'])]\n",
    "nodes_df.loc[duplicated_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05b652bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicate_node_id = [2024, 4987, 7669, 7921, 9900, 7888]\n",
    "\n",
    "# Remove both James Connolly\n",
    "james_id = [7656, 9880]\n",
    "\n",
    "for node_id in remove_duplicate_node_id:\n",
    "    assert len(edges_df[edges_df['Source'] == str(node_id)]) == 0 or len(edges_df[edges_df['Target'] == str(node_id)]) == 0\n",
    "network.remove_nodes_from(remove_duplicate_node_id+james_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c940b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any duplicates left\n",
    "nodes_nameURL_list = []\n",
    "for node in network.nodes(data=True):\n",
    "    title = node[1]['NameURL']\n",
    "    nodes_nameURL_list.append(title)\n",
    "assert len(nodes_nameURL_list) == len(set(nodes_nameURL_list)), \"There are still duplicate NameURL entries!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16634512",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* Get pages with #REDIRECT\n",
    "\n",
    "* For every page, get redirect link names and store them as an attribute to get correct links later\n",
    "{{Redirect|AR Rahman|the surah of the Quran|Ar-Rahman|other uses|Al rahman (disambiguation)}}\n",
    "\n",
    "* Handle not found pages manually and find new wiki pages\n",
    "\n",
    "* Create new attributes, newName and newLink for this\n",
    "\n",
    "* Update edges, check all redirect link names and new names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7491864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"#REDIRECT\\s*\\[\\[(.*?)\\]\\]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in list(network.nodes(data=True)):\n",
    "    nameURL = node[1]['NameURL']\n",
    "    file_path = Path(f\"wikipages/{nameURL}.txt\")\n",
    "    if not file_path.exists():\n",
    "        continue\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        wikitext = f.read()\n",
    "        match = re.search(regex, wikitext, re.IGNORECASE)\n",
    "        if match:\n",
    "            redirect_title = match.group(1)\n",
    "            network.nodes[node[0]]['redirectNameURL'] = redirect_title\n",
    "            try:\n",
    "                wikitext = get_wikitext(redirect_title)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching wikitext for {nameURL}: {e}\")\n",
    "                continue\n",
    "            with open(f'wikipages/{nameURL}.txt', 'w', encoding='utf-8') as f:\n",
    "                f.write(wikitext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d2f8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check is all redirects are resolved\n",
    "for node in network.nodes(data=True):\n",
    "    nameURL = node[1]['NameURL']\n",
    "    file_path = Path(f\"wikipages/{nameURL}.txt\")\n",
    "    if not file_path.exists():\n",
    "        continue\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        wikitext = f.read()\n",
    "        match = re.search(regex, wikitext, re.IGNORECASE)\n",
    "        assert not match, f\"Redirect still found in {nameURL}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14b8558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add wikicontent as a node attribute\n",
    "for node in network.nodes(data=True):\n",
    "    nameURL = node[1]['NameURL']\n",
    "    file_path = Path(f\"wikipages/{nameURL}.txt\")\n",
    "    if not file_path.exists():\n",
    "        nameURL = node[1].get('redirectNameURL', None)\n",
    "        if nameURL is None:\n",
    "            print(f\"\\n❌ Failure: '{file_path}' was NOT found as an attribute.\")\n",
    "            continue\n",
    "        file_path = Path(f\"wikipages/{nameURL}.txt\")\n",
    "        if not file_path.exists():\n",
    "            print(f\"\\n❌ Failure: '{file_path}' was NOT found.\")\n",
    "            continue\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        wikitext = f.read()\n",
    "        network.nodes[node[0]]['wikicontent'] = wikitext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acadbcf0",
   "metadata": {},
   "source": [
    "Handle case like Aaron Johnson or Fabio where there are multiple people with the same name but different Wikipedia pages\n",
    "\n",
    "* Also check if there are pages with short length, maybe a problem there too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "51c0eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Warning: 'wikipages/Klas_Pontus_Arnoldson.txt' has only 289 words.\n",
      "❌ Warning: 'wikipages/Omar_Suleiman.txt' has only 50 words.\n",
      "❌ Warning: 'wikipages/Mohammed_Omar.txt' has only 262 words.\n",
      "❌ Warning: 'wikipages/Vitus.txt' has only 271 words.\n",
      "❌ Warning: 'wikipages/Adrian_Smith.txt' has only 85 words.\n",
      "❌ Warning: 'wikipages/Jesse.txt' has only 258 words.\n",
      "❌ Warning: 'wikipages/Benjamin_Angus_Wright.txt' has only 209 words.\n",
      "❌ Warning: 'wikipages/Hermann_Müller_(politician).txt' has only 117 words.\n",
      "❌ Warning: 'wikipages/Mark_Webber.txt' has only 48 words.\n",
      "❌ Warning: 'wikipages/Rudolph_I_of_Habsburg.txt' has only 35 words.\n",
      "❌ Warning: 'wikipages/Baldwin_Spencer.txt' has only 26 words.\n",
      "❌ Warning: 'wikipages/Zengi.txt' has only 87 words.\n",
      "❌ Warning: 'wikipages/Daniel_Alves.txt' has only 34 words.\n",
      "❌ Warning: 'wikipages/Suleiman_II.txt' has only 30 words.\n",
      "❌ Warning: 'wikipages/Zico.txt' has only 160 words.\n",
      "❌ Warning: 'wikipages/Carlos_Sainz.txt' has only 56 words.\n",
      "❌ Warning: 'wikipages/Ben_Foster.txt' has only 63 words.\n",
      "❌ Warning: 'wikipages/Ricardo_Costa_(Portuguese_footballer).txt' has only 52 words.\n",
      "❌ Warning: 'wikipages/Constance_of_Sicily.txt' has only 54 words.\n",
      "❌ Warning: 'wikipages/Denis.txt' has only 298 words.\n",
      "❌ Warning: 'wikipages/Kevin_Doyle.txt' has only 46 words.\n",
      "❌ Warning: 'wikipages/Ay.txt' has only 266 words.\n",
      "❌ Warning: 'wikipages/Nikola_Kalinić.txt' has only 35 words.\n",
      "❌ Warning: 'wikipages/Xavi.txt' has only 173 words.\n",
      "❌ Warning: 'wikipages/Nani.txt' has only 166 words.\n",
      "❌ Warning: 'wikipages/Mardonius.txt' has only 53 words.\n",
      "❌ Warning: 'wikipages/Zosimus.txt' has only 249 words.\n",
      "❌ Warning: 'wikipages/Doda.txt' has only 169 words.\n",
      "❌ Warning: 'wikipages/Daniel.txt' has only 280 words.\n",
      "❌ Warning: 'wikipages/Martin_Kelly.txt' has only 69 words.\n",
      "❌ Warning: 'wikipages/Ben_Wallace.txt' has only 68 words.\n",
      "❌ Warning: 'wikipages/Lisandro_López.txt' has only 21 words.\n",
      "❌ Warning: 'wikipages/Asa.txt' has only 291 words.\n",
      "❌ Warning: 'wikipages/Kallikrates.txt' has only 292 words.\n",
      "❌ Warning: 'wikipages/ATB.txt' has only 259 words.\n",
      "❌ Warning: 'wikipages/Aaron_Johnson.txt' has only 78 words.\n",
      "❌ Warning: 'wikipages/Salif_Keïta.txt' has only 45 words.\n",
      "❌ Warning: 'wikipages/Igor_Smirnov.txt' has only 42 words.\n",
      "❌ Warning: 'wikipages/Maximiliano_Pereira.txt' has only 30 words.\n",
      "❌ Warning: 'wikipages/Brendan.txt' has only 76 words.\n",
      "❌ Warning: 'wikipages/Theuderic_IV.txt' has only 297 words.\n",
      "❌ Warning: 'wikipages/Frederik,_Crown_Prince_of_Denmark.txt' has only 124 words.\n",
      "\n",
      "Total files with less than 300 words: 42\n"
     ]
    }
   ],
   "source": [
    "# this is just for testing\n",
    "\n",
    "directory_path = Path(\"wikipages\")\n",
    "files_found_path = list(directory_path.glob(\"*.txt\"))\n",
    "output_path = Path(\"wikipages_less300.txt\")\n",
    "ambiguation_list_by_word = []\n",
    "for file_path in files_found_path:\n",
    "    try:\n",
    "        content = file_path.read_text(encoding='utf-8', errors='replace')\n",
    "        word_count = len(content.split())\n",
    "        if word_count < 300:\n",
    "            ambiguation_list_by_word.append(file_path)\n",
    "            with output_path.open(\"a\", encoding=\"utf-8\") as output_file:\n",
    "                output_file.write(f\"{content}\\n{\"+\"*300}\\n{\"+\"*300}\\n\")\n",
    "            print(f\"❌ Warning: '{file_path}' has only {word_count} words.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        continue\n",
    "print(f\"\\nTotal files with less than 300 words: {len(ambiguation_list_by_word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "989ab540",
   "metadata": {},
   "outputs": [],
   "source": [
    "disambiguation_regex = r\"\\{\\{\\s*(?:[^|}]*disambiguation|hndis|given name|surname|disambig|hndisambig|hndab)(?:\\|.*?)?\\}\\}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f79fef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Warning: 'wikipages/Omar_Suleiman.txt' contains a disambiguation template. Word count: 50\n",
      "❌ Warning: 'wikipages/Mohammed_Omar.txt' contains a disambiguation template. Word count: 262\n",
      "❌ Warning: 'wikipages/Vitus.txt' contains a disambiguation template. Word count: 271\n",
      "❌ Warning: 'wikipages/Adrian_Smith.txt' contains a disambiguation template. Word count: 85\n",
      "❌ Warning: 'wikipages/Jesse.txt' contains a disambiguation template. Word count: 258\n",
      "❌ Warning: 'wikipages/Hermann_Müller_(politician).txt' contains a disambiguation template. Word count: 117\n",
      "❌ Warning: 'wikipages/Mark_Webber.txt' contains a disambiguation template. Word count: 48\n",
      "❌ Warning: 'wikipages/Rudolph_I_of_Habsburg.txt' contains a disambiguation template. Word count: 35\n",
      "❌ Warning: 'wikipages/Baldwin_Spencer.txt' contains a disambiguation template. Word count: 26\n",
      "❌ Warning: 'wikipages/Zengi.txt' contains a disambiguation template. Word count: 87\n",
      "❌ Warning: 'wikipages/Daniel_Alves.txt' contains a disambiguation template. Word count: 34\n",
      "❌ Warning: 'wikipages/Suleiman_II.txt' contains a disambiguation template. Word count: 30\n",
      "❌ Warning: 'wikipages/Fabio.txt' contains a disambiguation template. Word count: 725\n",
      "❌ Warning: 'wikipages/Zico.txt' contains a disambiguation template. Word count: 160\n",
      "❌ Warning: 'wikipages/Ben_Johnson_(sprinter).txt' contains a disambiguation template. Word count: 344\n",
      "❌ Warning: 'wikipages/Carlos_Sainz.txt' contains a disambiguation template. Word count: 56\n",
      "❌ Warning: 'wikipages/Ben_Foster.txt' contains a disambiguation template. Word count: 63\n",
      "❌ Warning: 'wikipages/Ricardo_Costa_(Portuguese_footballer).txt' contains a disambiguation template. Word count: 52\n",
      "❌ Warning: 'wikipages/Constance_of_Sicily.txt' contains a disambiguation template. Word count: 54\n",
      "❌ Warning: 'wikipages/Denis.txt' contains a disambiguation template. Word count: 298\n",
      "❌ Warning: 'wikipages/Kevin_Doyle.txt' contains a disambiguation template. Word count: 46\n",
      "❌ Warning: 'wikipages/Yoshiki.txt' contains a disambiguation template. Word count: 444\n",
      "❌ Warning: 'wikipages/Ay.txt' contains a disambiguation template. Word count: 266\n",
      "❌ Warning: 'wikipages/Nikola_Kalinić.txt' contains a disambiguation template. Word count: 35\n",
      "❌ Warning: 'wikipages/Xavi.txt' contains a disambiguation template. Word count: 173\n",
      "❌ Warning: 'wikipages/Nani.txt' contains a disambiguation template. Word count: 166\n",
      "❌ Warning: 'wikipages/Mika.txt' contains a disambiguation template. Word count: 1297\n",
      "❌ Warning: 'wikipages/Rebecca.txt' contains a disambiguation template. Word count: 592\n",
      "❌ Warning: 'wikipages/Saleh.txt' contains a disambiguation template. Word count: 606\n",
      "❌ Warning: 'wikipages/Mardonius.txt' contains a disambiguation template. Word count: 53\n",
      "❌ Warning: 'wikipages/Zosimus.txt' contains a disambiguation template. Word count: 249\n",
      "❌ Warning: 'wikipages/Doda.txt' contains a disambiguation template. Word count: 169\n",
      "❌ Warning: 'wikipages/JoJo.txt' contains a disambiguation template. Word count: 895\n",
      "❌ Warning: 'wikipages/Daniel.txt' contains a disambiguation template. Word count: 280\n",
      "❌ Warning: 'wikipages/Martin_Kelly.txt' contains a disambiguation template. Word count: 69\n",
      "❌ Warning: 'wikipages/Ben_Wallace.txt' contains a disambiguation template. Word count: 68\n",
      "❌ Warning: 'wikipages/Lisandro_López.txt' contains a disambiguation template. Word count: 21\n",
      "❌ Warning: 'wikipages/Asa.txt' contains a disambiguation template. Word count: 291\n",
      "❌ Warning: 'wikipages/ATB.txt' contains a disambiguation template. Word count: 259\n",
      "❌ Warning: 'wikipages/Aaron_Johnson.txt' contains a disambiguation template. Word count: 78\n",
      "❌ Warning: 'wikipages/Salif_Keïta.txt' contains a disambiguation template. Word count: 45\n",
      "❌ Warning: 'wikipages/Igor_Smirnov.txt' contains a disambiguation template. Word count: 42\n",
      "❌ Warning: 'wikipages/Maximiliano_Pereira.txt' contains a disambiguation template. Word count: 30\n",
      "❌ Warning: 'wikipages/Abdul_Qadir.txt' contains a disambiguation template. Word count: 1459\n",
      "❌ Warning: 'wikipages/Brendan.txt' contains a disambiguation template. Word count: 76\n",
      "❌ Warning: 'wikipages/Frederik,_Crown_Prince_of_Denmark.txt' contains a disambiguation template. Word count: 124\n",
      "\n",
      "Total files with disambiguation templates: 46\n"
     ]
    }
   ],
   "source": [
    "directory_path = Path(\"wikipages\")\n",
    "files_found_path = list(directory_path.glob(\"*.txt\"))\n",
    "output_path = Path(\"wikipages_disambiguatiion_template.txt\")\n",
    "ambiguation_list_by_template = []\n",
    "for file_path in files_found_path:\n",
    "    try:\n",
    "        content = file_path.read_text(encoding='utf-8', errors='replace')\n",
    "        word_count = len(content.split())\n",
    "        if re.search(disambiguation_regex, content, re.IGNORECASE):\n",
    "            ambiguation_list_by_template.append(file_path)\n",
    "            with output_path.open(\"a\", encoding=\"utf-8\") as output_file:\n",
    "                output_file.write(f\"{content}\\n{\"+\"*300}\\n{\"+\"*300}\\n\")\n",
    "            print(f\"❌ Warning: '{file_path}' contains a disambiguation template. Word count: {word_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        continue\n",
    "print(f\"\\nTotal files with disambiguation templates: {len(ambiguation_list_by_template)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "34d08549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11332"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(network.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec1338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files with less than 300 words but no disambiguation template: 4\n",
      " - wikipages/Theuderic_IV.txt\n",
      " - wikipages/Kallikrates.txt\n",
      " - wikipages/Benjamin_Angus_Wright.txt\n",
      " - wikipages/Klas_Pontus_Arnoldson.txt\n"
     ]
    }
   ],
   "source": [
    "# this is just for testing\n",
    "diff = set(ambiguation_list_by_word) - set(ambiguation_list_by_template)\n",
    "print(f\"\\nFiles with less than 300 words but no disambiguation template: {len(diff)}\")\n",
    "for file in diff:\n",
    "    print(f\" - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f514d5",
   "metadata": {},
   "source": [
    "If you check, these pages are correct but just short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5da797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID 80 with NameURL Abdul_Qadir word count 1459 contains a disambiguation template.\n",
      "Node ID 95 with NameURL Baldwin_Spencer word count 26 contains a disambiguation template.\n",
      "Node ID 126 with NameURL Lisandro_López word count 21 contains a disambiguation template.\n",
      "Node ID 277 with NameURL Mark_Webber word count 48 contains a disambiguation template.\n",
      "Node ID 699 with NameURL Daniel_Alves word count 34 contains a disambiguation template.\n",
      "Node ID 714 with NameURL Fabio word count 725 contains a disambiguation template.\n",
      "Node ID 791 with NameURL Zico word count 160 contains a disambiguation template.\n",
      "Node ID 967 with NameURL Nani word count 166 contains a disambiguation template.\n",
      "Node ID 1174 with NameURL Nikola_Kalinić word count 35 contains a disambiguation template.\n",
      "Node ID 1381 with NameURL Frederik,_Crown_Prince_of_Denmark word count 124 contains a disambiguation template.\n",
      "Node ID 1481 with NameURL Omar_Suleiman word count 50 contains a disambiguation template.\n",
      "Node ID 2549 with NameURL ATB word count 259 contains a disambiguation template.\n",
      "Node ID 2719 with NameURL Hermann_Müller_(politician) word count 117 contains a disambiguation template.\n",
      "Node ID 3219 with NameURL Rudolph_I_of_Habsburg word count 35 contains a disambiguation template.\n",
      "Node ID 3787 with NameURL Brendan word count 76 contains a disambiguation template.\n",
      "Node ID 3810 with NameURL Kevin_Doyle word count 46 contains a disambiguation template.\n",
      "Node ID 3876 with NameURL Daniel word count 280 contains a disambiguation template.\n",
      "Node ID 3984 with NameURL Denis word count 298 contains a disambiguation template.\n",
      "Node ID 4744 with NameURL Vitus word count 271 contains a disambiguation template.\n",
      "Node ID 4765 with NameURL Ben_Johnson_(sprinter) word count 344 contains a disambiguation template.\n",
      "Node ID 4912 with NameURL Yoshiki word count 444 contains a disambiguation template.\n",
      "Node ID 4994 with NameURL Mika word count 1297 contains a disambiguation template.\n",
      "Node ID 5084 with NameURL Salif_Keïta word count 45 contains a disambiguation template.\n",
      "Node ID 5514 with NameURL Jesse word count 258 contains a disambiguation template.\n",
      "Node ID 5669 with NameURL Doda word count 169 contains a disambiguation template.\n",
      "Node ID 5834 with NameURL Ricardo_Costa_(Portuguese_footballer) word count 52 contains a disambiguation template.\n",
      "Node ID 6074 with NameURL Igor_Smirnov word count 42 contains a disambiguation template.\n",
      "Node ID 6557 with NameURL Carlos_Sainz word count 56 contains a disambiguation template.\n",
      "Node ID 6841 with NameURL Xavi word count 173 contains a disambiguation template.\n",
      "Node ID 7117 with NameURL Zengi word count 87 contains a disambiguation template.\n",
      "Node ID 7304 with NameURL Suleiman_II word count 30 contains a disambiguation template.\n",
      "Node ID 7839 with NameURL Aaron_Johnson word count 78 contains a disambiguation template.\n",
      "Node ID 7848 with NameURL Adrian_Smith word count 85 contains a disambiguation template.\n",
      "Node ID 8375 with NameURL Martin_Kelly word count 69 contains a disambiguation template.\n",
      "Node ID 9146 with NameURL Ben_Wallace word count 68 contains a disambiguation template.\n",
      "Node ID 9842 with NameURL Ben_Foster word count 63 contains a disambiguation template.\n",
      "Node ID 10785 with NameURL JoJo word count 895 contains a disambiguation template.\n",
      "Node ID 10880 with NameURL Asa word count 291 contains a disambiguation template.\n",
      "Node ID 10889 with NameURL Ay word count 266 contains a disambiguation template.\n",
      "Node ID 10932 with NameURL Constance_of_Sicily word count 54 contains a disambiguation template.\n",
      "Node ID 11063 with NameURL Mardonius word count 53 contains a disambiguation template.\n",
      "Node ID 11154 with NameURL Rebecca word count 592 contains a disambiguation template.\n",
      "Node ID 11259 with NameURL Zosimus word count 249 contains a disambiguation template.\n",
      "Node ID 11278 with NameURL Maximiliano_Pereira word count 30 contains a disambiguation template.\n",
      "Node ID 11325 with NameURL Saleh word count 606 contains a disambiguation template.\n",
      "\n",
      "Total nodes removed due to disambiguation templates: 45\n"
     ]
    }
   ],
   "source": [
    "removed_nodes = []\n",
    "nodes = list(network.nodes(data=True))\n",
    "for node in nodes:\n",
    "    node_id = node[0]\n",
    "    content = network.nodes[node_id].get('wikicontent', '')\n",
    "    word_count = len(content.split())\n",
    "    if re.search(disambiguation_regex, content, re.IGNORECASE):\n",
    "        print(f\"Node ID {node_id} with NameURL {network.nodes[node_id]['NameURL']} word count {word_count} contains a disambiguation template.\")\n",
    "        removed_nodes.append((node_id, network.nodes[node_id]['NameURL']))\n",
    "        network.remove_node(node_id)\n",
    "print(f\"\\nTotal nodes removed due to disambiguation templates: {len(removed_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "274f006c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11286"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(network.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d63e18",
   "metadata": {},
   "source": [
    "# Save network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c19e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(network, \"celebrities_clean.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7dea5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_without_content = network.copy()\n",
    "for node in network_without_content.nodes(data=True):\n",
    "    if 'wikicontent' in node[1]:\n",
    "        del node[1]['wikicontent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2597efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(network_without_content, \"celebrities_clean_without_content.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41798f55",
   "metadata": {},
   "source": [
    "# Update edges based on new wikipages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
